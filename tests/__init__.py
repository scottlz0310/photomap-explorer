"""
PhotoMap Explorer ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆè¨­å®š

This module provides test configuration and utilities for PhotoMap Explorer.
"""

import os
import sys
import tempfile
import shutil
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# ãƒ†ã‚¹ãƒˆç”¨è¨­å®š
TEST_CONFIG = {
    'temp_dir': None,
    'sample_images_dir': None,
    'test_output_dir': None,
    'performance_results_dir': None
}

def setup_test_environment():
    """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    TEST_CONFIG['temp_dir'] = tempfile.mkdtemp(prefix='photomap_test_')
    TEST_CONFIG['test_output_dir'] = os.path.join(TEST_CONFIG['temp_dir'], 'output')
    TEST_CONFIG['sample_images_dir'] = os.path.join(TEST_CONFIG['temp_dir'], 'sample_images')
    TEST_CONFIG['performance_results_dir'] = os.path.join(PROJECT_ROOT, 'tests', 'performance', 'results')
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs(TEST_CONFIG['test_output_dir'], exist_ok=True)
    os.makedirs(TEST_CONFIG['sample_images_dir'], exist_ok=True)
    os.makedirs(TEST_CONFIG['performance_results_dir'], exist_ok=True)
    
    print(f"âœ… ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†: {TEST_CONFIG['temp_dir']}")
    return TEST_CONFIG

def cleanup_test_environment():
    """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    if TEST_CONFIG['temp_dir'] and os.path.exists(TEST_CONFIG['temp_dir']):
        shutil.rmtree(TEST_CONFIG['temp_dir'])
        print(f"âœ… ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {TEST_CONFIG['temp_dir']}")

def create_sample_images():
    """ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ä½œæˆ"""
    from PIL import Image, ExifTags
    import random
    
    if not TEST_CONFIG['sample_images_dir']:
        setup_test_environment()
    
    # GPSåº§æ¨™ã®ä¾‹ï¼ˆæ±äº¬å‘¨è¾ºï¼‰
    sample_coordinates = [
        (35.6762, 139.6503),  # æ±äº¬é§…
        (35.6584, 139.7016),  # æ±äº¬ã‚¿ãƒ¯ãƒ¼
        (35.6593, 139.7006),  # å…­æœ¬æœ¨ãƒ’ãƒ«ã‚º
        (35.6751, 139.7648),  # ã‚¹ã‚«ã‚¤ãƒ„ãƒªãƒ¼
        (35.6586, 139.7454),  # æ¸‹è°·
    ]
    
    created_files = []
    
    for i, (lat, lon) in enumerate(sample_coordinates):
        # ç°¡å˜ãªç”»åƒä½œæˆ
        img = Image.new('RGB', (800, 600), color=(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)))
        
        # GPS EXIFãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹å ´åˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
        filename = f"test_image_{i+1:03d}.jpg"
        filepath = os.path.join(TEST_CONFIG['sample_images_dir'], filename)
        img.save(filepath, 'JPEG')
        created_files.append(filepath)
    
    print(f"âœ… ã‚µãƒ³ãƒ—ãƒ«ç”»åƒä½œæˆå®Œäº†: {len(created_files)}æš")
    return created_files

class TestReporter:
    """ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self):
        self.results = {
            'total_tests': 0,
            'passed': 0,
            'failed': 0,
            'errors': 0,
            'performance_metrics': {}
        }
    
    def add_result(self, test_name, status, duration=None, error=None):
        """ãƒ†ã‚¹ãƒˆçµæœã‚’è¿½åŠ """
        self.results['total_tests'] += 1
        
        if status == 'passed':
            self.results['passed'] += 1
        elif status == 'failed':
            self.results['failed'] += 1
        elif status == 'error':
            self.results['errors'] += 1
        
        if duration:
            self.results['performance_metrics'][test_name] = duration
    
    def add_performance_metric(self, metric_name, value, unit='ms'):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿½åŠ """
        self.results['performance_metrics'][f"{metric_name} ({unit})"] = value
    
    def generate_report(self):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        success_rate = (self.results['passed'] / self.results['total_tests'] * 100) if self.results['total_tests'] > 0 else 0
        
        report = f"""
ğŸ“Š PhotoMap Explorer ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ
=====================================

ğŸ¯ ç·åˆçµæœ
-----------
- ç·ãƒ†ã‚¹ãƒˆæ•°: {self.results['total_tests']}
- æˆåŠŸ: {self.results['passed']}
- å¤±æ•—: {self.results['failed']}
- ã‚¨ãƒ©ãƒ¼: {self.results['errors']}
- æˆåŠŸç‡: {success_rate:.1f}%

âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
------------------------
"""
        
        for metric, value in self.results['performance_metrics'].items():
            report += f"- {metric}: {value}\n"
        
        return report
    
    def save_report(self, filename=None):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not filename:
            timestamp = __import__('datetime').datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"test_report_{timestamp}.md"
        
        report_path = os.path.join(TEST_CONFIG['performance_results_dir'], filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(self.generate_report())
        
        print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
        return report_path

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¬ãƒãƒ¼ã‚¿ãƒ¼
test_reporter = TestReporter()
